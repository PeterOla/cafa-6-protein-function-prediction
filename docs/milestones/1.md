# ðŸš© Milestone 1: The Foundation & Baselines

**Date:** November 21, 2025  
**Status:** âœ… Completed

---

## ðŸŽ¯ The Goal
We are participating in a competition to predict the function of proteins.

*   **Input:** A protein sequence (a long string of letters like `MVLSPADKT...`).
*   **Output:** A list of "GO Terms" (functions) that this protein performs (e.g., `GO:0005524`).

### ðŸ¢ The Analogy: "The Job Recruiter"
Imagine you are a recruiter trying to predict a person's **Job Title** based solely on their **Resume text**.

*   **Protein Sequence** = The Resume (Raw text).
*   **GO Terms** = Job Titles (e.g., "Accountant", "Manager", "Python Dev").
    *   *Note: One person can have multiple jobs.*

> **ðŸ’¡ Knowledge Nugget: The "Multi-Label" Challenge**
> In standard AI (like distinguishing cats vs. dogs), an image is usually just *one* thing. In our case, a protein can have 1, 5, or even 50 functions! This is called **Multi-Label Classification**, and it's much harder because the model has to decide *how many* labels to pick, not just *which* one.

---

## ðŸš€ Our Journey So Far

### Phase 1: The Setup (The Filing Cabinet)
Before doing any predicting, we had to organize our messy data.

*   **What we did:** We built `loaders.py`.
*   **Analogy:** We bought a filing cabinet. We organized the 82,000 resumes (sequences) and the dictionary of job titles (GO terms) so we could pull them out easily.

### Phase 2: Baseline 1 - The "Lazy Guesser" (Frequency)
*   **The Strategy:** We looked at all the resumes and saw that "Accountant" was the most common job. So, for every new resume we saw, we just guessed "Accountant."
*   **The Code:** `baseline_frequency.py`
*   **The Result:** **F1 Score: 0.14**. Itâ€™s better than random guessing, but not smart.

> **ðŸ’¡ Knowledge Nugget: Why 0.14 isn't "Failing"**
> An F1 score of 0.14 sounds low (like 14% on a test), but in this specific competition, the top scientists in the world might only get 0.50 or 0.60. The "Random Guess" score here is effectively 0.00. So, 0.14 is actually a solid starting foothold!

### Phase 3: Baseline 2 - The "Copycat" (KNN)
*   **The Strategy:** We used a powerful AI tool (ESM-2) to read every resume and summarize it into a set of numbers (an **Embedding**).
    *   *Example:* It turns a 5-page resume into a summary like `[Experience: 8, Tech: 9, Management: 2]`.
    *   Then, for a new person, we found the **most similar summary** in our database and just copied their job title.
*   **The Code:** `baseline_embedding_knn.py`
*   **The Result:** **F1 Score: 0.17**. This is our **Current Best**. It works because similar resumes usually mean similar jobs.

> **ðŸ’¡ Knowledge Nugget: Homology vs. Embeddings**
> Biologists have done this "Copycat" strategy for decades using a tool called **BLAST** (matching letter-by-letter). Our method uses **Embeddings** (matching meaning-by-meaning). It's the difference between searching for "Software Engineer" (exact text) vs. searching for "Someone who writes code" (semantic meaning).

### Phase 4: Baseline 3 - The "Junior Recruiter" (MLP)
*   **The Strategy:** We hired a Junior Recruiter (a small Neural Network). We gave them the summaries (Embeddings) and asked them to *learn rules* to predict the job, rather than just copying the neighbor.
    *   *Example:* "If 'Tech' is high and 'Management' is high, they are probably a 'CTO'."
*   **The Upgrade:** You asked to use your **GPU** (a super-fast computer) and give the recruiter a better textbook (**Asymmetric Loss**) to handle the fact that most people *don't* have most jobs (lots of negatives).
*   **The Code:** `trainer.py` and `architecture.py`.
*   **The Result:** **F1 Score: 0.16**.
*   **Status:** The Junior Recruiter is trying hard, but they are currently slightly *worse* than the "Copycat" strategy. This is common! It's hard to beat a good similarity search.

---

## ðŸ—ï¸ The Scaffold (Your Project Structure)
Think of your folder structure as the different departments of your recruiting agency:

*   ðŸ“‚ **`data/`**: **The Archives.** Handles loading the raw resumes (Fasta files) and job lists (TSV files).
*   ðŸ“‚ **`models/`**: **The Staff.**
    *   `baseline_frequency.py`: The lazy intern.
    *   `baseline_embedding_knn.py`: The copycat.
    *   `architecture.py`: The Junior Recruiter (Neural Network).
*   ðŸ“‚ **`training/`**: **The Classroom.**
    *   `trainer.py`: The training program where the Recruiter learns.
    *   `loss.py`: The grading system (how we tell the Recruiter they are wrong).
*   ðŸ“‚ **`submission/`**: **The Mailroom.** Formats our predictions into the specific TSV format the competition judges require.

---

## ðŸ“ Where We Are Now
We have a fully functioning "Recruiting Agency" (Pipeline).

1.  âœ… We can load data.
2.  âœ… We can train a model on your powerful GPU.
3.  âœ… We can generate valid submission files.

**The Problem:**
Our "Junior Recruiter" (MLP) is looking at *summaries* (frozen embeddings) created by someone else (the pre-trained ESM-2 model). These summaries might be missing important details specific to *our* specific job market (GO terms).

### The Next Step: Fine-Tuning
We are going to stop using the pre-written summaries. We are going to take the big brain (ESM-2) and **teach it to read the resumes specifically for our task.**

This is **"Fine-Tuning."** It's like sending the Recruiter to medical school so they can understand a Doctor's resume perfectly, rather than just relying on a generic summary.

> **ðŸ’¡ Knowledge Nugget: Transfer Learning**
> We aren't training a brain from scratch (which would take millions of dollars). We are taking a brain that already knows "Protein Language" (ESM-2) and just teaching it "Protein Functions." This is called **Transfer Learning**, and it's the secret sauce of modern AI.
